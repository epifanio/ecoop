{
 "metadata": {
  "name": "ecoop_t1"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "!rm -rf cf.py ecooputil.py",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#%loadpy https://raw.github.com/epifanio/ecoop/master/cf.py\n#%%file cf.py",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#%loadpy https://raw.github.com/epifanio/ecoop/master/ecooputil.py\n#%%file cf.py",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#%%file ecooputil.py\n#!/usr/bin/python\n\nimport os\nimport sys\nfrom zipfile import ZipFile, ZIP_DEFLATED\nfrom contextlib import closing\nimport paramiko\nimport qrcode\nfrom IPython.core.display import HTML, Image\nfrom IPython.display import display, Javascript\nimport envoy\nfrom datetime import datetime\n\nclass shareUtil():\n    def zipdir(self, basedir, archivename, rm='no'):\n        \"\"\"\n        utility function to zip a single file or a directory\n        usage : zipdir(input, output)\n        @param basedir: input file or directory\n        @param archivename: output file.zip\n        @param rm: [yes, no], remove source file (optional, default=no)\n        \"\"\"\n        assert os.path.isdir(basedir)\n        with closing(ZipFile(archivename, \"w\", ZIP_DEFLATED)) as z:\n            for root, dirs, files in os.walk(basedir):\n                #NOTE: ignore empty directories\n                for fn in files:\n                    #print fn\n                    absfn = os.path.join(root, fn)\n                    zfn = absfn[len(basedir) + len(os.sep):] #XXX: relative path\n                    z.write(absfn, zfn)\n        if rm != 'no':\n            instruction = 'rm -rf %s' % basedir\n            os.system(instruction)\n\n    def uploadfile(self, username='epi', password='epi', hostname='localhost', port=22,\n                   inputfile=None, outputfile=None, link=False, apacheroot='/var/www/', zip=False, qr=False):\n        '''\n        utility to upload file on remote server using sftp protocol\n        usage : uploadfile(inputfile, outputfile)\n        @rtype : str\n        @param username: str - username on remote server\n        @param password: str - password to access remote server\n        @param hostname: str - hostname of remote server (default: localhost)\n        @param port: port number on remote server (default: 22)\n        @param inputfile: str - local path to the file to uploaded\n        @param outputfile: remote path to the file to upload\n        @param link: bolean [True, False] default False, print a link to download the file\n                                     (remote path needs to be in a web available directory)\n        @param apacheroot: path to apache root default to '/var/www/' required if link == True\n        @param zip: bolean deafault False, zip the output\n        @param qr: bolean deafault False, return qrcode as image\n        @return: link to uploaded file if link=True or qr image if qr=True & link=True, none if link is set to false\n        '''\n        if zip:\n            #print 'add zipfile'\n            zipfile = str(inputfile + '.zip')\n            self.zipdir(inputfile, zipfile)\n            inputfile = zipfile\n            #paramiko.util.log_to_file('/var/www/esr/paramiko.log')\n        client = paramiko.SSHClient()\n        client.set_missing_host_key_policy(paramiko.AutoAddPolicy())\n        client.connect(hostname, username=username, password=password)\n        transport = paramiko.Transport((hostname, port))\n        transport.connect(username=username, password=password)\n        sftp = paramiko.SFTPClient.from_transport(transport)\n        parts = outputfile.split('/')\n        for n in range(2, len(parts)):\n            path = '/'.join(parts[:n])\n            #print 'Path:', path,\n            sys.stdout.flush()\n            try:\n                s = sftp.stat(path)\n                #print 'mode =', oct(s.st_mode)\n            except IOError as e:\n                #print e\n                #print 'adding dir: ', path\n                sftp.mkdir(path)\n        try:\n            sftp.put(remotepath=outputfile, localpath=inputfile)\n            sftp.close()\n            transport.close()\n            print 'file uploaded'\n            if qr:\n                if link:\n                    pass\n                if not link:\n                    print 'WORNING: qrcode not generated, set the option link to True'\n            if link:\n                filelink = outputfile.replace(apacheroot, '')\n                link = 'http://' + os.path.normpath(hostname + '/' + filelink)\n                raw_html = '<a href=\"%s\" target=\"_blank\">ESR results</a>' % link\n                print 'results are now available for download at : ', link\n                image = None\n                if qr:\n                    imagefile = parts[-1].split('.')[0] + '.jpeg'\n                    qr = qrcode.QRCode(version=1, error_correction=qrcode.constants.ERROR_CORRECT_L, box_size=10, border=4)\n                    qr.add_data(link)\n                    qr.make(fit=True)\n                    img = qr.make_image()\n                    img.save(imagefile, \"JPEG\")\n                    print 'alive'\n                    image = Image(imagefile)\n                    return image\n                if not qr:\n                    return HTML(raw_html)\n        except IOError:\n            print \"Error: can\\'t find file or read data check if input file exist and or remote location is writable\"\n\n    def gistit(self, filename, jist='/usr/local/bin/jist', type='notebook'):\n        '''\n        use the jist utility to paste a txt file on github as gist and return a link to it\n        usage :  gistit(notebookfile)\n        @param filename: str - path to the a text file or notebook file (.json)\n        @param jist: str - path to the executable jist (default=/usr/local/bin/jist)\n        @param type: str - notebook, text\n        @return: return a link to gist if type=text, link to nbviewer if type=notebook\n        '''\n        try:\n            with open(filename):\n                link = None\n                jist = self.which(jist)\n                if jist:\n                    try:\n                        r = envoy.run('%s -p %s' % (jist, filename))\n                        if type == 'notebook':\n                            link = r.std_out.replace('\\n', '').replace('https://gist.github.com',\n                                                                       'http://nbviewer.ipython.org')\n                        if type == 'text':\n                            link = r.std_out.replace('\\n', '')\n                        return link\n                    except:\n                        print \"can't generate gist, check if jist works bycommand line with: jist -p filename\"\n                if not jist:\n                    print 'cannot find jist utility, check if it is in your path'\n        except IOError:\n            print 'input file %s not found' % filename\n\n    def get_id(self, suffix, makedir=True):\n        '''\n        generate a directory based on the suffix and a time stamp\n        output looks like : suffix_Thursday_26_September_2013_06_28_49_PM\n        usage: getID(suffix)\n        @param suffix: str - suffix for the directory to be generated,\n        @return: str - directory name\n        '''\n        ID = suffix + '_' + str(datetime.now().utcnow().strftime(\"%A_%d_%B_%Y_%I_%M_%S_%p\"))\n        if makedir:\n            self.ensure_dir(ID)\n        print 'session data directory : ID', ID\n        return ID\n\n    def ensure_dir(self, dir):\n        '''\n        make a directory on the file system if it does not exist\n        usage: ensure_dir(dir)\n        @param dir: str - path to a directory existent on the local filesystem\n        @return: None\n        '''\n        if not os.path.exists(dir):\n            os.makedirs(dir)\n\n    def save_notebook(self, ID, notebookname, web=None, notebookdir=None):\n        \"\"\"\n        Save the notebook file as html and or as gist\n        @param ID: directory name where to store the saved notebook\n        @param notebookname: name of the notebook\n        @param web:\n        @param notebookdir:\n        \"\"\"\n        if not notebookdir:\n            notebookdir = os.getcwd()\n        display(Javascript(\"IPython.notebook.save_notebook()\"))\n        notebookfile = os.path.join(notebookdir, notebookname)\n        savedir = os.path.join(os.getcwd(), ID)\n        command1 = 'cp %s %s' % (notebookfile, savedir)\n        newnotebook = os.path.join(savedir, notebookname)\n        command2 = 'ipython nbconvert -f html %s' % newnotebook\n        os.system(command1)\n        os.system(command2)\n        if web:\n            try:\n                self.gistit(notebookfile)\n            except IOError:\n                print \"can't genrate a gist\"\n\n    def which(self, program):\n        \"\"\"\n        Check if a program exist and return the full path\n        @param program: executable name or path to executable\n        @return: full path to executable\n        \"\"\"\n        def is_exe(fpath):\n            return os.path.isfile(fpath) and os.access(fpath, os.X_OK)\n        fpath, fname = os.path.split(program)\n        if fpath:\n            if is_exe(program):\n                return program\n        else:\n            for path in os.environ[\"PATH\"].split(os.pathsep):\n                path = path.strip('\"')\n                exe_file = os.path.join(path, program)\n                if is_exe(exe_file):\n                    return exe_file\n        return None",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#%loadpy https://raw.github.com/epifanio/ecoop/master/cf.py\n#%%file cf.py",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "##%%file cf.py\n#!/usr/bin/python\nimport os\nimport envoy\n\nfrom datetime import datetime\nimport numpy as np\nimport scipy.stats as sts\nimport statsmodels.api as sm\n\nlowess = sm.nonparametric.lowess\nfrom scipy.interpolate import interp1d\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom ecooputil import shareUtil as EU\neu = EU()\nclass cfData():\n    def __init__(self):\n        self.x = 'Hello'\n\n    def nao_get(self, url=\"https://climatedataguide.ucar.edu/sites/default/files/climate_index_files/nao_station_djfm.txt\",\n                save=None, csvout='nao.csv'):\n        \"\"\"\n        read NAO data from url and return a pandas dataframe\n        @param url: url to data online default is set to :\n                    https://climatedataguide.ucar.edu/sites/default/files/climate_index_files/nao_station_djfm.txt\n        @param save: directory where to save raw data as csv\n        @return: naodata as pandas dataframe\n        \"\"\"\n        try:\n            naodata = pd.read_csv(url, sep='  ', header=0, skiprows=0, index_col=0, parse_dates=True, skip_footer=1)\n            print 'dataset used: %s', url\n            if save:\n                eu.ensure_dir(save)\n                output = os.path.join(save, csvout)\n                naodata.to_csv(output, sep=',', header=True, index=True, index_label='Date')\n                print 'nao data saved in :', output\n            return naodata\n        except IOError:\n            print 'unable to fetch the data, check if %s is a valid address and data is conform to AMO spec, for info about data spec. see [1]', url\n            # try cached version / history-linked-uri\n\n\n    def nin_get(self, url='http://www.cpc.ncep.noaa.gov/data/indices/sstoi.indices', save=None, csvout='nin.csv'):\n        \"\"\"\n        read NIN data from url and return a pandas dataframe\n        @param url: url to data online default is set to : http://www.cpc.ncep.noaa.gov/data/indices/sstoi.indices\n        @param save: directory where to save raw data as csv\n        @return: nindata as pandas dataframe\n        \"\"\"\n        try:\n            ts_raw = pd.read_table(url, sep=' ', header=0, skiprows=0, parse_dates=[['YR', 'MON']], skipinitialspace=True,\n                                   index_col=0, date_parser=parse)\n            print 'dataset used: %s', url\n            ts_year_group = ts_raw.groupby(lambda x: x.year).apply(lambda sdf: sdf if len(sdf) > 11 else None)\n            ts_range = pd.date_range(ts_year_group.index[0][1], ts_year_group.index[-1][1] + pd.DateOffset(months=1),\n                                     freq=\"M\")\n            ts = pd.DataFrame(ts_year_group.values, index=ts_range, columns=ts_year_group.keys())\n            ts_fullyears_group = ts.groupby(lambda x: x.year)\n            nin_anomalies = (ts_fullyears_group.mean()['ANOM.3'] - sts.nanmean(\n                ts_fullyears_group.mean()['ANOM.3'])) / sts.nanstd(ts_fullyears_group.mean()['ANOM.3'])\n            nin_anomalies = pd.DataFrame(nin_anomalies.values, index=pd.to_datetime([str(x) for x in nin_anomalies.index]))\n            nin_anomalies = nin_anomalies.rename(columns={'0': 'nin'})\n            nin_anomalies.columns = ['nin']\n            if save:\n                eu.ensure_dir(save)\n                output = os.path.join(save, csvout)\n                nin_anomalies.to_csv(output, sep=',', header=True, index=True, index_label='Date')\n                print 'data saved as', output\n            return nin_anomalies\n        except IOError:\n            print 'unable to fetch the data, check if %s is a valid address and data is conform to AMO spec, for info about data spec. see [1]', url\n            # try cached version / history-linked-uri\n\n\n    def parse(self, yr, mon):\n        \"\"\"\n        Convert year and month to a datatime object, day hardcoded to 2nd day of each month\n        @param yr: year date integer or string\n        @param mon: month date integer or string\n        @return: datatime object (time stamp)\n        \"\"\"\n        date = datetime(year=int(yr), day=2, month=int(mon))\n        return date\n\n\n    def amo_get(self, url='http://www.cdc.noaa.gov/Correlation/amon.us.long.data', save=None, csvout='amo.csv'):\n        \"\"\"\n        read AMO data from url and return a pandas dataframe\n        @param url: url to data online default is set to : http://www.cdc.noaa.gov/Correlation/amon.us.long.data\n        @param save: directory where to save raw data as csv\n        @return: amodata as pandas dataframe\n        \"\"\"\n        try:\n            ts_raw = pd.read_table(url, sep=' ', skiprows=1,\n                                   names=['year', 'jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct',\n                                          'nov', 'dec'], skipinitialspace=True, parse_dates=True, skipfooter=4, index_col=0)\n            print 'dataset used: %s', url\n            ts_raw.replace(-9.99900000e+01, np.NAN, inplace=True)\n            amodata = ts_raw.mean(axis=1)\n            amodata.name = \"amo\"\n            amodata = pd.DataFrame(amodata)\n            if save:\n                eu.ensure_dir(save)\n                output = os.path.join(save, csvout)\n                amodata.to_csv(output, sep=',', header=True, index=True, index_label='Date')\n                print 'data saved as', output\n            return amodata\n        except:\n            print 'doh'\n            print 'unable to fetch the data, check if %s is a valid address and data is conform to AMO spec, for info about data spec. see [1]' % url\n            # try cached version / history-linked-uri\n\nclass cfPlot():\n    def plot_index(self, data, name='Index',\n                   nb=True, datarange=None,\n                   xticks=10, xticks_fontsize=10,\n                   dateformat=False, figsize=(10, 8),\n                   xmargin=True, ymargin=True,\n                   legend=True, smoother=None,\n                   output=None, dpi=300,\n                   grid=True, xlabel='Year',\n                   ylabel='', title='',\n                   win_size=10, win_type='boxcar',\n                   center=False, std=0.1,\n                   beta=0.1, power=1, width=1,\n                   min_periods=None, freq=None,\n                   scategory=None, frac=1. / 3, it=3, figsave=None):\n        \"\"\"\n        Function to plot the Climate Forcing indicator for the ESR 2013, it follow graphic guidlines from the past ESR\n        adding functionalities like :\n        several kind of smoothline with different\n        @param data: pandas dataframe - input data\n        @param name: string - name used as dataframe index\n        @param nb: bolean if True the function is optimized to render the png inside a notebook\n        @param datarange: list of 2 integer for mak min year\n        @param xticks: integer xtick spacing default=10\n        @param xticks_fontsize: integer xticks fontsize default=10\n        @param dateformat: boolean if True set the xticks labels in date format\n        @param figsize: tuple figure size default (10, 8)\n        @param xmargin: bolean default True\n        @param ymargin: bolean default True\n        @param legend: bolean default True\n        @param smoother: tuple (f,i)\n        @param output: directory where to save output default None\n        @param dpi: integer\n        @param grid: bolean default True\n        @param xlabel: string default 'Year'\n        @param ylabel: string default ''\n        @param title: string default ''\n        @param win_size: integer default 10\n        @param win_type: string default 'boxcar'\n        @param center: bolean default False\n        @param std: float default 0.1\n        @param beta: float default 0.1\n        @param power: integer default 1\n        @param width: integer default 1\n        @param min_periods: None\n        @param freq: None\n        @param scategory: string default 'rolling'\n        @param frac: float default 0.6666666666666666 Between 0 and 1. The fraction of the data used when estimating each y-value.,\n        @param it: integer default 3 The number of residual-based reweightings to perform.\n\n        \"\"\"\n        try:\n            assert type(data) == pd.core.frame.DataFrame\n            #x = data.index.year\n            #y = data.values\n            if datarange:\n            #if datarange != None :\n                mind = np.datetime64(str(datarange[0]))\n                maxd = np.datetime64(str(datarange[1]))\n                newdata = data.ix[mind:maxd]\n                x = newdata.index.year\n                y = newdata.values\n            else:\n                x = data.index.year\n                y = data.values\n            x_p = x[np.where(y >= 0)[0]]\n            y_p = y[np.where(y >= 0)[0]]\n            x_n = x[np.where(y < 0)[0]]\n            y_n = y[np.where(y < 0)[0]]\n            fig = plt.figure(figsize=figsize)\n            ax1 = fig.add_subplot(111)\n            ax1.bar(x_n, y_n, 0.8, facecolor='b', label=name + ' < 0')\n            ax1.bar(x_p, y_p, 0.8, facecolor='r', label=name + ' > 0')\n            ax1.grid(grid)\n            if ylabel != '':\n                ax1.set_ylabel(ylabel)\n            else:\n                ax1.set_ylabel(name)\n            if xlabel != '':\n                ax1.set_xlabel(xlabel)\n            else:\n                ax1.set_xlabel(xlabel)\n            if title == '':\n                ax1.set_title(name)\n            else:\n                ax1.set_title(title)\n            ax1.axhline(0, color='black', lw=1.5)\n            if xmargin:\n                ax1.set_xmargin(0.1)\n            if ymargin:\n                ax1.set_xmargin(0.1)\n            if legend:\n                ax1.legend()\n            if not figsave:\n                figsave = name + '.png'\n            if scategory == 'rolling':\n                newy = self.rolling_smoother(data, stype=smoother, win_size=win_size, win_type=win_type, center=center, std=std,\n                                        beta=beta, power=power, width=width)\n                ax1.plot(newy.index.year, newy.values, lw=3, color='g')\n            if scategory == 'expanding':\n                newy = self.expanding_smoother(data, stype=smoother, min_periods=min_periods, freq=freq)\n                ax1.plot(newy.index.year, newy.values, lw=3, color='g')\n            if scategory == 'lowess':\n                x = np.array(range(0, len(data.index.values))).T\n                newy = pd.Series(lowess(data.values.flatten(), x, frac=frac, it=it).T[1], index=data.index)\n                ax1.plot(newy.index.year, newy, lw=3, color='g')\n                ## interp 1D attempt\n                xx = np.linspace(min(data.index.year), max(data.index.year), len(newy))\n                f = interp1d(xx, newy)\n                xnew = np.linspace(min(data.index.year), max(data.index.year), len(newy) * 4)\n                f2 = interp1d(xx, newy, kind='cubic')\n                #xnew = np.linspace(min(data.index.values), max(data.index.values), len(newy)*2)\n                ax1.plot(xx, newy, 'o', xnew, f(xnew), '-', xnew, f2(xnew), '--')\n                ##\n            if scategory == 'ewma':\n                print 'todo'\n            plt.xticks(data.index.year[::xticks].astype('int'), data.index.year[::xticks].astype('int'),\n                       fontsize=xticks_fontsize)\n            plt.autoscale(enable=True, axis='both', tight=True)\n            if dateformat:\n                fig.autofmt_xdate(bottom=0.2, rotation=75, ha='right')\n            if output:\n                eu.ensure_dir(output)\n                ffigsave = os.path.join(output, figsave)\n                plt.savefig(ffigsave, dpi=dpi)\n                print 'graph saved in: ', ffigsave\n                if scategory:\n                    smoutput = name + '_' + scategory + '.csv'\n                    if smoother:\n                        smoutput = name + '_' + scategory + '_' + smoother + '.csv'\n                    smoutput = os.path.join(output, smoutput)\n                    if scategory == 'lowess':\n                        #print type(data)\n                        newdataframe = data.copy(deep=True)\n                        newdataframe['smooth'] = pd.Series(newy, index=data.index)\n                        newdataframe.to_csv(smoutput, sep=',', header=True, index=True, index_label='Year')\n                    else:\n                        newy.to_csv(smoutput, sep=',', header=True, index=True, index_label='Year')\n                    print name, 'smothed data saved in : ', smoutput\n            if nb:\n                fig.subplots_adjust(left=-1.0)\n                fig.subplots_adjust(right=1.0)\n            plt.show()\n        except AssertionError:\n            if type(data) != pd.core.frame.DataFrame:\n                print 'input data not campatible, it has to be of type : pandas.core.frame.DataFrame'\n            print 'data not loaded correctly'\n\n\n    def rolling_smoother(self, data, stype='rolling_mean', win_size=10, win_type='boxcar', center=False, std=0.1, beta=0.1,\n                         power=1, width=1):\n        \"\"\"\n        Perform a espanding smooting on the data for a complete help refer to http://pandas.pydata.org/pandas-docs/dev/computation.html\n        @param data:\n        @param stype:\n        @param win_size:\n        @param win_type:\n        @param center:\n        @param std:\n        @param beta:\n        @param power:\n        @param width:\n        smoothing types:\n            ROLLING :\n                rolling_count\tNumber of non-null observations\n                rolling_sum\tSum of values\n                rolling_mean\tMean of values\n                rolling_median\tArithmetic median of values\n                rolling_min\tMinimum\n                rolling_max\tMaximum\n                rolling_std\tUnbiased standard deviation\n                rolling_var\tUnbiased variance\n                rolling_skew\tUnbiased skewness (3rd moment)\n                rolling_kurt\tUnbiased kurtosis (4th moment)\n                rolling_window\tMoving window function\n                    window types:\n                        boxcar\n                        triang\n                        blackman\n                        hamming\n                        bartlett\n                        parzen\n                        bohman\n                        blackmanharris\n                        nuttall\n                        barthann\n                        kaiser (needs beta)\n                        gaussian (needs std)\n                        general_gaussian (needs power, width)\n                        slepian (needs width)\n        \"\"\"\n        if stype == 'count':\n            newy = pd.rolling_count(data, win_size)\n        if stype == 'sum':\n            newy = pd.rolling_sum(data, win_size)\n        if stype == 'mean':\n            newy = pd.rolling_mean(data, win_size)\n        if stype == 'median':\n            newy = pd.rolling_median(data, win_size)\n        if stype == 'min':\n            newy = pd.rolling_min(data, win_size)\n        if stype == 'max':\n            newy = pd.rolling_max(data, win_size)\n        if stype == 'std':\n            newy = pd.rolling_std(data, win_size)\n        if stype == 'var':\n            newy = pd.rolling_var(data, win_size)\n        if stype == 'skew':\n            newy = pd.rolling_skew(data, win_size)\n        if stype == 'kurt':\n            newy = pd.rolling_kurt(data, win_size)\n        if stype == 'window':\n            if win_type == 'kaiser':\n                newy = pd.rolling_window(data, win_size, win_type, center=center, beta=beta)\n            if win_type == 'gaussian':\n                newy = pd.rolling_window(data, win_size, win_type, center=center, std=std)\n            if win_type == 'general_gaussian':\n                newy = pd.rolling_window(data, win_size, win_type, center=center, power=power, width=width)\n            else:\n                newy = pd.rolling_window(data, win_size, win_type, center=center)\n        return newy\n\n\n    def expanding_smoother(self, data, stype='rolling_mean', min_periods=None, freq=None):\n        \"\"\"\n        Perform a expanding smooting on the data for a complete help refer to http://pandas.pydata.org/pandas-docs/dev/computation.html\n        @param data: pandas dataframe input data\n        @param stype: soothing type\n        @param min_periods: periods\n        @param freq: frequence\n        smoothing types:\n        expanding_count\tNumber of non-null observations\n        expanding_sum\tSum of values\n        expanding_mean\tMean of values\n        expanding_median\tArithmetic median of values\n        expanding_min\tMinimum\n        expanding_max\tMaximum\n        expandingg_std\tUnbiased standard deviation\n        expanding_var\tUnbiased variance\n        expanding_skew\tUnbiased skewness (3rd moment)\n        expanding_kurt\tUnbiased kurtosis (4th moment)\n        \"\"\"\n        if stype == 'count':\n            newy = pd.expanding_count(data, min_periods=min_periods, freq=freq)\n        if stype == 'sum':\n            newy = pd.expanding_sum(data, min_periods=min_periods, freq=freq)\n        if stype == 'mean':\n            newy = pd.expanding_mean(data, min_periods=min_periods, freq=freq)\n        if stype == 'median':\n            newy = pd.expanding_median(data, min_periods=min_periods, freq=freq)\n        if stype == 'min':\n            newy = pd.expanding_min(data, min_periods=min_periods, freq=freq)\n        if stype == 'max':\n            newy = pd.expanding_max(data, min_periods=min_periods, freq=freq)\n        if stype == 'std':\n            newy = pd.expanding_std(data, min_periods=min_periods, freq=freq)\n        if stype == 'var':\n            newy = pd.expanding_var(data, min_periods=min_periods, freq=freq)\n        if stype == 'skew':\n            newy = pd.expanding_skew(data, min_periods=min_periods, freq=freq)\n        if stype == 'kurt':\n            newy = pd.expanding_kurt(data, min_periods=min_periods, freq=freq)\n        return newy\n\nclass cfPrint():\n    def makepdf(self, ID, cf='climate_forcing.txt', naotxt='nao.txt', amotxt='amo.txt', nbname='None', nbviewerlink=None,\n                naodatalink=None, amodatalink=None, naofigfile='nao.png', amofigfile='amo.png', verbose=False):\n        \"\"\"\n        generate a PDF from a latext template ( it is intended to be just an eaxmple to show how to use a latex\n        template to generate a pdf dinamically embedding link to URI inside the document)\n        example for the first section of the ESR.\n        NOTE :\n        the data and uri can easly point to an RDF description of this document\n        (the document needs its own ontology stored on a triple store)\n        @param ID:\n        @param cf:\n        @param naotxt:\n        @param amotxt:\n        @param nbname:\n        @param nbviewerlink:\n        @param naodatalink:\n        @param amodatalink:\n        @param naofigfile:\n        @param amofigfile:\n        \"\"\"\n        template = \"\"\"\\documentclass{article}\n        \\usepackage{multicol}\n        \\usepackage[english]{babel}\n        \\usepackage{blindtext}\n        \\usepackage[pdftex]{graphicx}\n        \\usepackage{graphicx}\n        \\usepackage{wrapfig}\n        \\usepackage{hyperref}\n        \\usepackage{fancyvrb}\n        \\usepackage[utf8]{inputenc}\n        \\\\begin{document}\n        \\\\begin{twocolumn}\n        \\section{Climate Forcing}\n        \\input{%s}\n        \\subsection{North Atlantic Oscillation Index}\n        \\inputencoding{utf8}\n        \\input{%s}\n        \\\\begin{figure}[h]\n        {\\includegraphics[width=60mm]{%s}}\n        \\caption{North Atlantic Oscillation - \\href{%s}{data} -\n        \\href{%s}{code}.}\n        \\end{figure}\n        \\subsection{Atlantic Multidecadal Oscillation}\n        \\inputencoding{utf8}\n        \\input{%s}\n        \\\\begin{figure}[h]\n        {\\includegraphics[width=60mm]{%s}}\n        \\caption{Atlantic Multidecadal Oscillation - \\href{%s}{data} - \\href{%s}{code}.}\n        \\end{figure}\n        \\end{twocolumn}\n        \\end{document}\"\"\"\n        #naofigfile = os.path.join(ID, naofigfile)\n        #amofigfile = os.path.join(ID, amofigfile)\n        #if os.path.isfile(naofigfile) and os.path.isfile(amofigfile):\n        #cf = cf\n        #naotxt = naotxt\n        #amotxt = amotxt\n        listafile = [naofigfile, amofigfile, cf, naotxt, amotxt]\n        '''\n        for i in listafile:\n            print i\n            try:\n                with open(i):\n                    pass\n            except IOError:\n                print 'file %s not found' % i\n                print 'make PDF aborted'\n                return\n        '''\n        linestring = template % (\n            cf, naotxt, naofigfile, naodatalink[0], nbviewerlink, amotxt, amofigfile, amodatalink[0], nbviewerlink)\n        #newfile = open(os.path.join(ID, 'climate_forcing.tex'), 'w')\n        newfile = open('climate_forcing.tex', 'w')\n        newfile.write(linestring)\n        newfile.close()\n        \n        instruction = 'pdflatex -output-directory=%s %s' % (ID, os.path.join(ID, 'climate_forcing.tex'))\n        print instruction\n        r = envoy.run(instruction, timeout=12)\n        if verbose:\n            print r.std_out.strip()#.split('\\n')\n        instruction2 = 'rm -rf %s/climate_forcing.aux %s/climate_forcing.log %s/climate_forcing.out' % (ID, ID, ID)\n        r = envoy.run(instruction2, timeout=12)\n        if verbose:\n            print r.std_out.strip()#.split('\\n')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "from ecooputil import shareUtil\nfrom cf import cfData, cfPlot, cfPrint",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "util = shareUtil()\ncfd = cfData()\ncfp = cfPlot()\ncfprint = cfPrint()\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "ID = util.get_id('Climate-forcing_pdf')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "##Climate Forcing\n\nClimate patterns over the North Atlantic are important drivers of oceanographic conditions and ecosystem states. \nSteadily increasing atmospheric carbon dioxide levels can not only affect climate on global and regional scales \nbut alter critical aspects of ocean chemistry. Here, we describe the atmospheric forcing mechanisms related \nto climate in this region including large-scale atmospheric pressure systems, natural ocean temperature cycles in the North Atlantic, \ncomponents of the large-scale circulation of the Atlantic Ocean, and issues related to ocean acidification."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%file {ID}/climate_forcing.txt\nClimate patterns over the North Atlantic are important drivers of oceanographic conditions and ecosystem states. \nSteadily increasing atmospheric carbon dioxide levels can not only affect climate on global and regional scales \nbut alter critical aspects of ocean chemistry. Here, we describe the atmospheric forcing mechanisms related \nto climate in this region including large-scale atmospheric pressure systems, natural ocean temperature cycles in the North Atlantic, \ncomponents of the large-scale circulation of the Atlantic Ocean, and issues related to ocean acidification.",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "***North Atlantic Osccilation (NAO)***\n\nClimate and weather over the North Atlantic are strongly influenced by the relative strengths \nof two large-scale atmospheric pressure cells -- the Icelandic Low and the Azores High [4]. \nAs the relative strengths of these two pressure systems vary, characteristic patterns of temperature, precipitation, and wind fields are observed. \nAn index of this dipole pattern has been developed based on the standardized difference in sea level pressure between Lisbon, Portugal and Reykjav\u00edk, \nIceland in the winter (December-February; see Glossary for a description of methods used to create standardized indicators). \nThis North Atlantic Oscillation (NAO) index has been related to key oceanographic and ecological processes in the North Atlantic basin [5].  \nWhen the NAO index is high (positive NAO state), the westerly winds shift northward and increase in strength. \nAdditionally, there is an increase in precipitation over southeastern Canada, the eastern seaboard of the United States, \nand northwestern Europe. Water temperatures are cool off Labrador and northern Newfoundland, influencing the formation of Deep Labrador Slope water, \nbut warm off the United States. \nConversely, when the NAO index is low (negative NAO state), there is a southward shift and decrease in westerly winds, decreased storminess, \nand drier conditions over southeastern Canada, the eastern United States, and northwestern Europe. \nWater temperatures are warmer off Labrador and Newfoundland, but cooler off the eastern United States. \nSince 1972, the NAO has primarily been in a positive state (Figure 1), although notable short-term reversals to a negative state have been observed during this period. \nChanges in the NAO have been linked to changes in plankton community composition in the North Atlantic, reflecting changes in both the distribution \nand abundance of warm and cold-temperate species."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%file {ID}/nao.txt\nClimate and weather over the North Atlantic are strongly influenced by the relative strengths \nof two large-scale atmospheric pressure cells -- the Icelandic Low and the Azores High [4]. \nAs the relative strengths of these two pressure systems vary, characteristic patterns of temperature, precipitation, and wind fields are observed. \nAn index of this dipole pattern has been developed based on the standardized difference in sea level pressure between Lisbon, Portugal and Reykjav\u00edk, \nIceland in the winter (December-February; see Glossary for a description of methods used to create standardized indicators). \nThis North Atlantic Oscillation (NAO) index has been related to key oceanographic and ecological processes in the North Atlantic basin [5].  \nWhen the NAO index is high (positive NAO state), the westerly winds shift northward and increase in strength. \nAdditionally, there is an increase in precipitation over southeastern Canada, the eastern seaboard of the United States, \nand northwestern Europe. Water temperatures are cool off Labrador and northern Newfoundland, influencing the formation of Deep Labrador Slope water, \nbut warm off the United States. \nConversely, when the NAO index is low (negative NAO state), there is a southward shift and decrease in westerly winds, decreased storminess, \nand drier conditions over southeastern Canada, the eastern United States, and northwestern Europe. \nWater temperatures are warmer off Labrador and Newfoundland, but cooler off the eastern United States. \nSince 1972, the NAO has primarily been in a positive state (Figure 1), although notable short-term reversals to a negative state have been observed during this period. \nChanges in the NAO have been linked to changes in plankton community composition in the North Atlantic, reflecting changes in both the distribution \nand abundance of warm and cold-temperate species.",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "naodata = cfd.nao_get(save=ID, csvout=\"nao.csv\")\ncfp.plot_index(name='NAO_lowess', xticks=10, xticks_fontsize=10, \n               data=naodata, nb='y', scategory='lowess', frac=1./6, it=6, \n               output=ID, dateformat=True, figsave=\"nao.png\")",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "***Atlantic Multidecadal Oscillation (AMO)***\n\nMultidecadal patterns in sea surface temperature (SST) in the North Atlantic are represented\nby the Atlantic Multidecadal Oscillation (AMO) index. \nThe AMO signal is based on spatial patterns in SST variability after removing the effects of anthropogenic forcing on temperature, \nrevealing natural long term cycles in SST.\nThe AMO is characterized by warm and cool phases [6] with periods of approximately 20-40 years. \nThe AMO index is related to air temperatures and rainfall over North America and Europe and is associated \nwith changes in the frequency of droughts in North America and the frequency of severe hurricane events. \nThe AMO is thought to be related to the North Atlantic branch of the deep thermohaline circulation \n(for more see The Gulf Stream below) which is in turn directly related to dynamics of the Gulf Stream.\nThe AMO index shows a relatively cool period starting in the early 1960s, extending through the mid 1990s. \nSince 1997, the AMO has been in a warm phase (Figure 2). \nIf past patterns continue to hold, the warm phase will potentially continue for the next several decades."
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "%%file {ID}/amo.txt\nMultidecadal patterns in sea surface temperature (SST) in the North Atlantic are represented by the Atlantic Multidecadal Oscillation (AMO) index. \nThe AMO signal is based on spatial patterns in SST variability after removing the effects of anthropogenic forcing on temperature, \nrevealing natural long term cycles in SST.\nThe AMO is characterized by warm and cool phases [6] with periods of approximately 20-40 years. \nThe AMO index is related to air temperatures and rainfall over North America and Europe and is associated \nwith changes in the frequency of droughts in North America and the frequency of severe hurricane events. \nThe AMO is thought to be related to the North Atlantic branch of the deep thermohaline circulation \n(for more see The Gulf Stream below) which is in turn directly related to dynamics of the Gulf Stream.\nThe AMO index shows a relatively cool period starting in the early 1960s, extending through the mid 1990s. \nSince 1997, the AMO has been in a warm phase (Figure 2). \nIf past patterns continue to hold, the warm phase will potentially continue for the next several decades.",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "# fake for shutdown\nnaodata = cfd.nao_get(save=ID, csvout=\"amo.csv\")\ncfp.plot_index(name='AMO_lowess', xticks=10, xticks_fontsize=10, \n               data=naodata, nb='y', scategory='lowess', frac=1./6, it=6, \n               output=ID, dateformat=True, figsave=\"amo.png\")",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "#amodata = cfd.amo_get(save=ID)\n#cfp.plot_index(name='AMO_lowess', data=amodata, nb='y', scategory='lowess', \n#               frac=1./6,it=6, output=ID, dateformat=True)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "nb_name = \"ecoop_t1.ipynb\"\nutil.save_notebook(ID, nb_name)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import os\nnb_name = 'ecoop_t1.ipynb'\nnao_datafile = os.path.join(ID,'nao.csv')\namo_datafile = os.path.join(ID,'amo.csv')\n\nnbviewerlink = util.gistit(filename=nb_name, jist='/usr/local/bin/jist', type='notebook')\nnaodatalink = util.gistit(filename=nao_datafile, jist='/usr/local/bin/jist', type='text')\namodatalink = util.gistit(filename=amo_datafile, jist='/usr/local/bin/jist', type='text')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "amofigfile= ID+'/amo.png'\nnaofigfile=ID+'/nao.png'\n\ncf = ID+'/climate_forcing.txt'\namotxt = ID+'/amo.txt'\nnaotxt = ID+'/nao.txt'",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "def cftemplate(texfile):\n    template = \"\"\"\\documentclass{article}\n        \\usepackage{multicol}\n        \\usepackage[english]{babel}\n        \\usepackage{blindtext}\n        \\usepackage[pdftex]{graphicx}\n        \\usepackage{graphicx}\n        \\usepackage{wrapfig}\n        \\usepackage{hyperref}\n        \\usepackage{fancyvrb}\n        \\usepackage[utf8]{inputenc}\n        \\\\begin{document}\n        \\\\begin{twocolumn}\n        \\section{Climate Forcing}\n        \\input{%s}\n        \\subsection{North Atlantic Oscillation Index}\n        \\inputencoding{utf8}\n        \\input{%s}\n        \\\\begin{figure}[h]\n        {\\includegraphics[width=60mm]{%s}}\n        \\caption{North Atlantic Oscillation - \\href{%s}{data} -\n        \\href{%s}{code}.}\n        \\end{figure}\n        \\subsection{Atlantic Multidecadal Oscillation}\n        \\inputencoding{utf8}\n        \\input{%s}\n        \\\\begin{figure}[h]\n        {\\includegraphics[width=60mm]{%s}}\n        \\caption{Atlantic Multidecadal Oscillation - \\href{%s}{data} - \\href{%s}{code}.}\n        \\end{figure}\n        \\end{twocolumn}\n        \\end{document}\"\"\"\n    linestring = template % (\n            cf, naotxt, naofigfile, naodatalink, nbviewerlink, amotxt, amofigfile, amodatalink, nbviewerlink)\n    #newfile = open(os.path.join(ID, 'climate_forcing.tex'), 'w')\n    newfile = open(texfile, 'w')\n    newfile.write(linestring)\n    newfile.close()",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "cftemplate('climate_forcing.tex')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "!pdflatex -output-directory={ID} climate_forcing.tex\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "ls {ID}",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "username = 'epifanio'\npassword = 'xxxxxxxxxxx'\nhostname = 'xxxxxxxxxx'\nport = 22\ninputfile = ID\noutputfile = '/var/www/esr/%s' % ID",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "eu.uploadfile(username=username, password=password, hostname=hostname, port=port, inputfile=inputfile,outputfile=outputfile, zip=True, link=True, qr=True)\n",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": "####Source code used :\n[ecoop](https://raw.github.com/epifanio/ecoop/)"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "eu.save_notebook(ID, nb_name)",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "import time\ntime.sleep(5)\neu.gistit(filename='ESR_pdf_pandas.ipynb', jist='/usr/local/bin/jist', type='notebook')",
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": "",
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}